Title: Cased-Based Reasoning
Date: 2007-10-29 22:31
Slug: cased-based-reasoning

There are a lot of theories in artificial intelligence, attempting to
explain a plethora of phenomenon. I guess I am relatively easily
persuaded every time I hear a new theory. This time it's one of my
professor's spiel on case-based reasoning (CBR).

CBR is a model of how humans can adapt to so many different situations.
We can survive in an unfamiliar city perfectly well, we can write essays
on different topics without too much pain. Some people will argue that
we have different knowledge (say, a set of rules) for writing essays,
and for navigating cities. CBR<span id="__firefox-findbar-search-id"
style="padding:0;background-color:yellow;color:black;display:inline;font-size:inherit;"></span>
argues that there's a more abstract meta-theory behind it all: that we
learn from experience.

Put it this way, it seems really obvious. Of course we learn from
experience! The theory goes on to say that we don't do logical inference
and reasoning on all possible choices in a given situation, but only
change what we have done before to suit the situation. So when we face a
problem, we have to find a similar situation that we have solved before,
then look at the plan and reason with that plan to see what should be
changed.

If you are still totally un-convinced (or at least want some evidence),
consider what you do in school. When you learn math, or physics or any
science, you do exercises. Why? So you get practice. How does that
translate to CBR? You're broadening the number of cases you can reason
from. The more previous plans you have to approach a problem, the less
actual thinking (reasoning with the plan) you actually have to do, until
it becomes "automatic." Business schools and law schools teach cases,
which serve the same purpose as textbook exercises in math. When
teaching we give different examples of the same abstract idea, and what
do we hope the students do? Eventually abstract out the idea from all
these cases.

I'm not saying that's a definite proof of humans are case-based
reasoners at its base, but it's strong evidence for it.

One interesting side effect of building a system that does CBR<span
id="__firefox-findbar-search-id"
style="padding:0;background-color:yellow;color:black;display:inline;font-size:inherit;"></span>
is the seemingly simple, "find a similar situation." If CBR is to work,
that would imply a highly abstract mechanism for making analogies. It's
not that if you've looked for keys before you use the same plan to look
for keys again, but it will also apply if you look for your wallet, your
credit card, and any number of other things. Without this systematic
(and highly efficient) find and match system, CBR<span
id="__firefox-findbar-search-id"
style="padding:0;background-color:yellow;color:black;display:inline;font-size:inherit;"></span>
would fail.

One of the things this reminds me of is a program I learned about last
year, called the Structure Mapping Engine, or SME for short. This time
it's a model of analogy making. It assumes that analogies are made on
the relationships between objects, but not on the objects itself, and
that the deeper and more numerous these relationships are, the stronger
the analogy. The mapping from lost keys to lost wallets is a shallow
analogy, but something like applying the traffic network to a computer
network is a deep analogy. Of for that matter, how we use "shallow" and
"deep" to describe analogies, as though it was an ocean of thought.

Whether these examples of linguistic metaphors provide evidence that all
learning is based on metaphors is another issue entirely. Interested
readers can start with
[<cite class="book" style="font-style:normal;">George
Lakoff</cite>](http://en.wikipedia.org/wiki/George_Lakoff).

Besides having the ability to make analogies, there is another brain
function required for CBR to function: memories. The way CBR relies on
structural similarities between the present and the past reminds me of
something else: schemas, a model of how we make memories. The schema
theory is really a sort of case-based reasoning for memory. We have
memories of a general event - say, what it means to eat at a
restaurant - and then when ever we visit an actual restaurant, we have
new episodic memory. The schema theory says that we don't remember each
and every restaurant visit individually, but instead use the general
event to help reduce the number of things we remember. We don't need to
remember that the waiter came to us at this restaurant, because that
happens no matter which restaurant we're at. In other words, we only
remember what is different about this new memory.

The trade off for remember less things is of course that we remember
less details. If you go to a restaurant too often, you'll eventually mix
up what happened on which trip. Schema theory accounts for this by
saying that some of the details were generalized, and lost its
connection to the individual event.

Now here's something I'm interested in. For CBR and schemas, there
remains one big problem. How do we learn the "original" case or memory?
It can't be that we were born with a schema of how restaurants work, or
a plan for what to do if we lose stuff. There has to be something which
made the first case or schema, a meta-meta-theory of learning if you
will. And I'm curious what that is.

