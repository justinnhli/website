Title: Answers of the Weeks
Date: 2009-08-24 17:20
Slug: answers-of-the-weeks

**What is the difference between hurricanes, typhoons, and maelstroms?**

Hurricanes are basically large storm systems (aka [tropical
cyclone](http://en.wikipedia.org/wiki/Tropical_cyclone)).
[Typhoons](http://en.wikipedia.org/wiki/Pacific_typhoon) are just
hurricanes which form in the Pacific ocean; as far as I can tell, it's
just a naming difference.

[Maelstroms](http://en.wikipedia.org/wiki/Pacific_typhoon) are giant
whirlpools; they have nothing to do with the above.

**How do 3D glasses work?**

3D glasses allow movies to be turned into
"[stereograms](http://en.wikipedia.org/wiki/Stereogram)". Humans (and
most animals, I assume) have depth perception because each of our two
eyes sees slightly different things. This is most clearly demonstrated
if you put a finger in front of your nose. If you then focus on
something far away, you will have two semi-transparent fingers. This
comes from the brain trying to compensate for the blocked view, and
piecing information from the two eyes together.

Cute trick - take a hollow, see-through, cylindrical tube (like a used
toilet paper roll), and put it up to one eye. Now, take your hand, and
put it along the tube in front of the other eye. Open both eyes. If
you're doing this correctly, you should see a "hole" in your hand. It's
the same principle as the two "fingers" above - your brain fills in the
what should be behind the hand, and since it only knows what your other
eye can see through the tube, that's the only part it fills in.

Anyway, back to stereograms and 3D movies. In the old days, 3D pictures
are created with [color-filtered
glasses](http://en.wikipedia.org/wiki/Stereoscopy#Complementary_color_anaglyphs).
Two images of different colors are projected onto the movie screen, and
when people put 3D glasses on, each eye sees only one of the colored
pictures - because the filter blocks out the other color. By presenting
each eye with a slightly different image, the illusion of depth is
created. In the two images, things that should be "closer" would have
more horizontal displacement, while things that should be "further"
would have less. This can be demonstrated by moving the finger back and
forth, while still staring at something far away. The further you extend
your finger, the closer the two "fingers" appear.

What my question was really getting at was the new, polarized, 3D
glasses. I watched Pixar's Up in those, and noticed while standing in
line that the glasses only darken when paired with one lens and turned
to a certain angle, but it would not darken with the other lens at all.
We knew it was [polarized](http://en.wikipedia.org/wiki/Polarization),
but we thought it would be [linearly
polarized](http://en.wikipedia.org/wiki/Stereoscopy#Linearly_polarized_glasses)
at first. If that was the case though, the lens should darken regardless
of which other lens it was paired with. I thought they were [circularly
polarized](http://en.wikipedia.org/wiki/Stereoscopy#Circularly_polarized_glasses),
which would explain the odd pairing thing, but I never did find out why
it would be darkest at a certain angle.

**Does truth exist?**

This question was suggested to me by a friend. Clearly, the answer to
this one would not be as... objectively truthful most other questions. I
can, however, give my personal belief: yes.

I do believe in an objective truth. To me it's simple: either the trees,
the mountains, and my laptop all exist, or I'm a brain in a vat and
hallucinating all this, or even I'm part of a strange dream of a giant
frog. Whichever one of these is true - and I'm not saying that I know
which one is - the basic idea remains that one of them is true. Of
course, it could be that none of those are correct, but it's hard to
imagine a reality where there is no truth at all. It would almost be a
paradox to call it a reality at that point.

Whether we, as humans, would ever know the truth is a completely
different question.

**Why do humans have social needs?**

As far as I can tell, it's evolutionary. This [section of
Wikipedia](http://en.wikipedia.org/wiki/Belongingness#Evolutionary_perspectives)
gives a fairly simple answer.

I actually made a mistake in the list of questions; the question of
whether AIs can become a human's best friend should have been under this
question of social needs. That was the true point of asking this
question: if social needs could be met without physical contact (for
example, through the phone, through email, IM, etc.), then it is almost
inevitable humans will eventually befriend an AI.

Let me attack the conditions first. Could human social needs be
satisfied without physical contact? I think so. In the old days people
have pen pals and write letters to family members in far away places.
There is satisfaction in doing those things, and it could only be social
in nature. Nowadays people have phones, email, IM, Facebook, etc. which
makes it even easier to keep up with people without their physical
existance.

A deeper question could be asked as to how advanced the AI has to be.
Now that people are used to computers and the idea of AI, it would have
to be quite advanced. When AI was just being invented, however, people
were willing to believe that they were interacting with a human. Just
look at the first [ELIZA](http://en.wikipedia.org/wiki/ELIZA) tests.
People got attached to the computer, despite being told how it works and
that it's just a computer program. That's one of the big downfalls of
the [Turing test](http://en.wikipedia.org/wiki/Turing_test) - that
people are too willing to believe. For the purpose of meeting social
needs, however, this willingness to believe might be exactly what is
needed.

On another level, and also speaking personally, the AI would have to be
quite advanced for me to be satisfied. I'm interested in people's
stories, not just discussions on various topics. Sure, a lot of my
conversations with people have a philosophical leaning, but it's
interesting because they have experiences which led them to their
believes. Without this experience, it's no different from reading a dry
book which simply lays out the argument - or it should more properly
called the plan of attack, because there wouldn't be any argument at
all.

That said, I believe we will eventually have the technology to create
AIs which have their own - albeit not physical - histories and stories.

